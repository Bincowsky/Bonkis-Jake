{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Time Series Forecasting with PyTorch\n",
    "\n",
    "This Jupyter Notebook provides a full implementation of training an LSTM model using PyTorch on your pivot table dataset. The steps include data preparation, model definition, training, and evaluation.\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Data Preparation](#1)\n",
    "   - Import Libraries\n",
    "   - Load and Preprocess Data\n",
    "2. [Define Dataset Class](#2)\n",
    "3. [Split Data into Training and Validation Sets](#3)\n",
    "4. [Create DataLoaders](#4)\n",
    "5. [Define the LSTM Model](#5)\n",
    "6. [Initialize Model, Loss Function, and Optimizer](#6)\n",
    "7. [Training Loop](#7)\n",
    "8. [Evaluate the Model](#8)\n",
    "9. [Save the Model](#9)\n",
    "10. [Conclusion](#10)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## 1. Data Preparation\n",
    "\n",
    "### Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Preprocess Data\n",
    "\n",
    "Assuming your pivot table dataset in \"../data/processed/2023_complete_pivot.parquet\", with dates as the index and country-brand pairs as columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>Aldovia-AIMST</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>Aldovia-AIMST</td>\n",
       "      <td>0.006284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>Aldovia-AIMST</td>\n",
       "      <td>0.123459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>Aldovia-AIMST</td>\n",
       "      <td>0.055607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>Aldovia-AIMST</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date             id     value\n",
       "0 2013-01-01  Aldovia-AIMST  0.000000\n",
       "1 2013-01-02  Aldovia-AIMST  0.006284\n",
       "2 2013-01-03  Aldovia-AIMST  0.123459\n",
       "3 2013-01-04  Aldovia-AIMST  0.055607\n",
       "4 2013-01-05  Aldovia-AIMST  0.000000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df_pivot = pd.read_parquet(\"../data/processed/2023_complete_pivot.parquet\")\n",
    "\n",
    "# Reset index to turn the date into a column\n",
    "df_pivot = df_pivot.reset_index()\n",
    "\n",
    "# Rename the 'index' column to 'date'\n",
    "df_pivot = df_pivot.rename(columns={'index': 'date'})\n",
    "\n",
    "# Melt the DataFrame to long format\n",
    "df = df_pivot.melt(id_vars=['date'], var_name='id', value_name='value')\n",
    "\n",
    "# Sort by 'id' and 'date'\n",
    "df = df.sort_values(['id', 'date']).reset_index(drop=True)\n",
    "\n",
    "# Convert 'date' to datetime if not already\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Display the first few rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "## 2. Define Dataset Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, sequences, targets):\n",
    "        self.sequences = sequences\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Convert to torch tensors\n",
    "        sequence = torch.FloatTensor(self.sequences[idx]).unsqueeze(-1)\n",
    "        target = torch.FloatTensor([self.targets[idx]])\n",
    "        return sequence, target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "## 3. Split Data into Training and Validation Sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training samples: 6975716\n",
      "Total validation samples: 1685552\n"
     ]
    }
   ],
   "source": [
    "# Determine the cutoff date for the split (e.g., last 20% for validation)\n",
    "# Convert cutoff_date to numpy.datetime64\n",
    "cutoff_date = np.datetime64(df['date'].quantile(0.8))\n",
    "\n",
    "# Define sequence length\n",
    "sequence_length = 30  # Adjust based on your data\n",
    "\n",
    "# Initialize lists for training and validation data\n",
    "train_sequences = []\n",
    "train_targets = []\n",
    "val_sequences = []\n",
    "val_targets = []\n",
    "\n",
    "for name, group in df.groupby('id'):\n",
    "    group = group.sort_values('date').reset_index(drop=True)\n",
    "    values = group['value'].values\n",
    "    dates = group['date'].values\n",
    "    cutoff_index = np.searchsorted(dates, cutoff_date)\n",
    "    \n",
    "    # Training data\n",
    "    for i in range(cutoff_index - sequence_length):\n",
    "        seq = values[i:i+sequence_length]\n",
    "        target = values[i+sequence_length]\n",
    "        train_sequences.append(seq)\n",
    "        train_targets.append(target)\n",
    "    \n",
    "    # Validation data\n",
    "    for i in range(cutoff_index, len(values) - sequence_length):\n",
    "        seq = values[i:i+sequence_length]\n",
    "        target = values[i+sequence_length]\n",
    "        val_sequences.append(seq)\n",
    "        val_targets.append(target)\n",
    "\n",
    "print(f'Total training samples: {len(train_sequences)}')\n",
    "print(f'Total validation samples: {len(val_sequences)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "## 4. Create DataLoaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64  # Adjust based on your hardware capabilities\n",
    "\n",
    "# Create dataset instances\n",
    "train_dataset = TimeSeriesDataset(train_sequences, train_targets)\n",
    "val_dataset = TimeSeriesDataset(val_sequences, val_targets)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a>\n",
    "## 5. Define the LSTM Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMForecastingModel(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=64, num_layers=2):\n",
    "        super(LSTMForecastingModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Define LSTM layer\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "        # Define output layer\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden and cell states\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "\n",
    "        # Get the output from the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a>\n",
    "## 6. Initialize Model, Loss Function, and Optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = LSTMForecastingModel().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"7\"></a>\n",
    "## 7. Training Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20  # Adjust based on your needs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    for sequences, targets in train_loader:\n",
    "        sequences = sequences.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(sequences)\n",
    "        loss = criterion(outputs.squeeze(), targets)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for sequences, targets in val_loader:\n",
    "            sequences = sequences.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(sequences)\n",
    "            loss = criterion(outputs.squeeze(), targets)\n",
    "            val_losses.append(loss.item())\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "          f'Train Loss: {np.mean(train_losses):.4f}, '\n",
    "          f'Val Loss: {np.mean(val_losses):.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"8\"></a>\n",
    "## 8. Evaluate the Model\n",
    "\n",
    "### Calculate Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "actuals = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sequences, targets in val_loader:\n",
    "        sequences = sequences.to(device)\n",
    "        outputs = model(sequences)\n",
    "        predictions.extend(outputs.squeeze().cpu().numpy())\n",
    "        actuals.extend(targets.cpu().numpy())\n",
    "\n",
    "mae = mean_absolute_error(actuals, predictions)\n",
    "rmse = mean_squared_error(actuals, predictions, squared=False)\n",
    "\n",
    "print(f'Validation MAE: {mae:.4f}')\n",
    "print(f'Validation RMSE: {rmse:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first 100 predictions vs actuals\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(actuals[:100], label='Actual')\n",
    "plt.plot(predictions[:100], label='Predicted')\n",
    "plt.legend()\n",
    "plt.title('Actual vs Predicted Values')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Value')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"9\"></a>\n",
    "## 9. Save the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'lstm_forecasting_model.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"10\"></a>\n",
    "## 10. Conclusion\n",
    "\n",
    "You've successfully trained an LSTM model on your pivot table dataset using PyTorch. You can now use this model to make predictions on future data or further refine it by tuning hyperparameters or incorporating additional features.\n",
    "\n",
    "---\n",
    "\n",
    "## Additional Notes\n",
    "\n",
    "- **Adjust Hyperparameters**: Experiment with `sequence_length`, `hidden_size`, `num_layers`, `batch_size`, and `num_epochs` to optimize performance.\n",
    "- **Scaling Data**: If your data has varying scales, consider scaling or normalizing it.\n",
    "- **Early Stopping**: Implement early stopping to prevent overfitting if necessary.\n",
    "- **Feature Engineering**: Even without exogenous variables, adding features like day of the week or month can help capture temporal patterns.\n",
    "\n",
    "## Example: Making Future Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_future(model, initial_sequence, prediction_length):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    sequence = initial_sequence.copy()\n",
    "    \n",
    "    for _ in range(prediction_length):\n",
    "        seq_input = torch.FloatTensor(sequence[-sequence_length:]).unsqueeze(0).unsqueeze(-1).to(device)\n",
    "        with torch.no_grad():\n",
    "            pred = model(seq_input)\n",
    "        pred_value = pred.item()\n",
    "        predictions.append(pred_value)\n",
    "        sequence = np.append(sequence, pred_value)\n",
    "    return predictions\n",
    "\n",
    "# Example usage:\n",
    "# Get the last sequence from the validation data\n",
    "latest_sequence = val_sequences[-1]\n",
    "future_predictions = predict_future(model, latest_sequence, prediction_length=7)\n",
    "\n",
    "print(\"Future Predictions:\", future_predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
